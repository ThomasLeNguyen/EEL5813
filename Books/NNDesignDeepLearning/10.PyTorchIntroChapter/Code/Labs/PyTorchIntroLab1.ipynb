{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NNDesignDeepLearning/NNDesignDeepLearning/blob/master/10.PyTorchIntroChapter/Code/LabSolutions/PyTorchIntroLab1_Solution.ipynb)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Introduction Lab 1 -- Getting Started\n",
    "\n",
    "This objective of this PyTorchFlow lab is to help you become familiar with the basics of using PyTorch to load data, create convolution networks, train the networks and display the results. If you haven't already done so, run the cells in the `PyTorchFlowIntroChapter.ipynb` Jupyter Notebook to prepare for this lab.\n",
    "\n",
    "Some of the cells in this notebook are prefilled with working code. In addition, there will be cells with missing code (labeled `# TODO`), which you will need to complete. If you need additional cells, you can use the `Insert` menu at the top of the page.\n",
    "\n",
    "## Loading Modules\n",
    "\n",
    "We begin by loading some useful modules."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "For this lab we will use a famous data set -- MNIST. This is a large database of handwritten digits. It contains 60,000 training images and 10,000 testing images. Each image consists of arrays of 28x28 pixels. The original website for the data, which describes the dataset in detail, and records accuracies using various machine learning strategies, can be found [here](http://yann.lecun.com/exdb/mnist/). The data set can be accessed easily using `torchvision.datasets`, as illustrated in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the next cell, print out the number of examples in the training and test sets, the shape of the first feature and the first label."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Length of Training Data\n",
    "# TODO\n",
    "print()\n",
    "# Length of Testing Data\n",
    "# TODO\n",
    "print()\n",
    "# The shape of the first feature\n",
    "# TODO\n",
    "print()\n",
    "# The first label\n",
    "# TODO\n",
    "print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now plot the first feature, to see if it matches the label."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "plt.imshow(training_data[0][0][0], cmap='gray')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Put the training and testing data into DataLoaders. Use a batch size of 100 for both sets, and shuffle the training data, but not the test data."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO\n",
    "BATCH_SIZE =\n",
    "train_loader =\n",
    "test_loader ="
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Model\n",
    "\n",
    "Now that the data is loaded, the next step is to construct the model. Create a method that uses the module subclass method to construct a network with two convolution layers and two fully connected layers and returns the constructed model. The function `nn.Conv2d()` is used to create the convolution layers. The important arguments are\n",
    "\n",
    "1. `in_channels` -- number of input feature maps\n",
    "2. `out_channels` -- number of output feature maps\n",
    "3. `kernel_size`\n",
    "4. `stride`\n",
    "5. `padding`\n",
    "\n",
    "The parameters `kernel_size`, `stride`, and `padding` can either be:\n",
    "* a single int – in which case the same value is used for the height and width dimension\n",
    "* a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension\n",
    "\n",
    "The network should have the following components:\n",
    "1. Convolution with 32 feature maps, 3x3 kernel, stride of 1 and no padding.\n",
    "2. ReLU activation.\n",
    "3. Convolution with 64 feature maps, 3x3 kernel, stride of 1 and no padding.\n",
    "4. ReLU activation.\n",
    "5. Max pooling layer using `F.max_pool2d(x, 2)`.\n",
    "6. Dropout with activation probability of 0.25.\n",
    "7. Convert to vector with `torch.flatten(x,1)`\n",
    "8. Fully connected layer with 128 neurons, using `nn.Linear`.\n",
    "9. ReLU activation.\n",
    "10. Dropout with activation probability of 0.5.\n",
    "11. Fully connected layer with 10 neurons, using `nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the CNN model\n",
    "# TODO\n",
    "class cnn_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn_model, self).__init__()\n",
    "        # TODO\n",
    "        self.conv1 =\n",
    "        self.conv2 =\n",
    "        self.dropout1 =\n",
    "        self.dropout2 =\n",
    "        self.fc1 =\n",
    "        self.fc2 =\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        output = x\n",
    "        return output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the method you just created to construct a model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "model = cnn_model()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "After constructing the model, print a summary."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(model)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Network\n",
    "\n",
    "The first step in training the network is to select the optimizer. Use `Adam` as the training function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO\n",
    "optimizer ="
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Assign the loss function as `nn.CrossEntropyLoss()`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "loss_fn ="
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Write a training loop. First, use a GPU if one is available. Train for 10 epochs, using the train_loader created above. Every 100 iterations, print out the training loss for the current minibatch, and save the loss for later plotting."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "total_loss =  []\n",
    "ind =  []\n",
    "for epoch in range(10):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            total_loss.append(loss.item())\n",
    "            ind.append(batch_idx + epoch*len(train_loader)/BATCH_SIZE)\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Plot the loss that you saved in the training loop."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.plot(total_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Trained Model\n",
    "\n",
    "In a loop of minibatches, using the test_loader, compute the overall accuracy of the network on the test set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Testing loop\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        # TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To get some insight into what the network has learned, plot the kernels of the 32 feature maps in the first layer of the network. You can get the weights of that layer uisng `model1.conv1.weight.data.cpu().numpy()`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Access the first convolutional layer\n",
    "# TODO\n",
    "first_conv_layer =\n",
    "\n",
    "# Get the weights of the layer\n",
    "# TODO\n",
    "weights =\n",
    "\n",
    "# Visualize the kernels\n",
    "fig, axes = plt.subplots(nrows=8, ncols=4)\n",
    "for i in range(32):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    ax.imshow(weights[i, 0], cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Do these kernels give you any insight into how the network is identifying the different numerals?\n",
    "\n",
    "Another way to understand the operation of the network is to look at the output of the feature maps for a specific input. In the next code block, select a single image from the test loader and apply it to the network. Then plot the outputs of the 32 feature maps in the first layer. You can access the outputs of the feature maps using `model1.conv1(image).cpu()`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the output of the first convolutional layer\n",
    "# TODO\n",
    "first_batch =\n",
    "image =\n",
    "output =\n",
    "\n",
    "# Visualize feature maps\n",
    "for i in range(output.shape[0]):\n",
    "    plt.subplot(8, 4, i+1)  # Adjust grid size as needed\n",
    "    plt.imshow(output[i].detach().numpy(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "After the model is trained to your satisfaction, save the model so that it can be used in the second lab. It is possible to save the entire model, but it is recommended to save just the model’s learned parameters, which are stored in `model.state_dict()`. This can be done with `torch.save(model.state_dict(), PATH)`.\n",
    "\n",
    "To load the model later, you need to first create an instance of the model, for example, by using `model = cnn_model()`. Then you can load the parameters using `model.load_state_dict(torch.load(PATH, weights_only=True))`.\n",
    "\n",
    "In the next cell, save the model. We will load the model back in the second PyTorch lab."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path = os.getcwd()\n",
    "os.makedirs('../Model' , exist_ok=True)\n",
    "#data_path = '/media/martin/Storage/github/DeepLearning/10.PyTorchIntroChapter/Code/data/'\n",
    "model_path = '../Model/'\n",
    "# TODO\n",
    "torch.save()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Further\n",
    "\n",
    "Experiment with different network architectures. Try to find the architecture that gives you the best accuracy. Investigate the following.\n",
    "\n",
    "1. Increase the size of the convolution kernels, and display the kernels. Do the shapes of the kernels become more intuitive?\n",
    "1. Increase the number of feature maps in the convolution layers. Does the testing accuracy increase?\n",
    "1. What if you add another convolution layer? Do you get better results increasing the number of neurons in each layer, or the number of layers (assuming the overal number of weights stays the same)?\n",
    "1. Try using batch normalization and removing the dropout. How does the test accuracy change?\n",
    "1. How small can you make the network and still achieve 98% test accuracy.\n",
    "1. Train with and without the GPU. How much speedup, if any, does the GPU give you?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
